{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APMTH 207: Advanced Scientific Computing: \n",
    "## Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "## Homework #5\n",
    "**Harvard University**<br>\n",
    "**Spring 2017**<br>\n",
    "**Instructors: Rahul Dave**<br>\n",
    "**Due Date: ** Thursday, March 2nd, 2017 at 11:59pm\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your final answers as well as your iPython notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 1: Monte Carlo and Simulation Revisited\n",
    "In Homework #2, we used simulation to compute the expected values of functions of random variables. That is, given a random variable $X$, defined over $\\mathbb{R}$, distributed according to the pdf $f_X$, and given a real-valued function of $X$, $h(X)$, we approximated $\\mathbb{E}[h(X)]$ as follows\n",
    "$$\n",
    "\\mathbb{E}[h(X)] = \\int_{\\mathbb{R}} h(x)f_X(x) dx \\approx \\frac{1}{n} \\sum_{i=1}^n h(X_i), \\quad X_i \\sim f_X\n",
    "$$\n",
    "\n",
    "Now, suppose that, instead of being given the distribution $f_X$ and $h(X)$, you were simply asked to evaluate the following complex integral:\n",
    "$$\n",
    "I=\\int_{0}^{\\infty} \\frac{x^4\\, \\sin\\left(\\sqrt{\\ln{(x+1)}}\\right)e^{-x}}{2+(x-4)^2} \\, dx \n",
    "$$\n",
    "A clever way to apply our Monte Carlo techniques would be to split the integrand as $h(x)f_X(x)$, and then approximate the integral as we have done in Homework #2:\n",
    "$$\n",
    "I = \\int_{0}^{\\infty} h(x)\\,f_X(x) dx  \\approx \\frac{1}{N} \\sum\\limits_{i=1}^{N} h(x_i)$$ \n",
    "where the values of $x$'s are now drawn from $g(x)$. \n",
    "\n",
    "Alternatively we can approximate the integral as \n",
    "$\\hat{I} \\approx \\frac{1}{N} \\sum\\limits_{i=1}^{N} g(X_i) $\n",
    "where the $X_i$'s are independently drawn from $f_X$.\n",
    "\n",
    "### Part A:\n",
    "- In order for our Monte Carlo approximation of $I$ to be as accurate as possible, name a few general properties that  $f_X(x)$ and $h(x)$ should satisfy.\n",
    "\n",
    "- Rewrite your integrand as a product $h(x)f_X(x)$. Explain how you chose the functions $h$ and $f_X$ (specifically, you should address how your choices satisfy the properties you outlined in the first bullet).\n",
    "\n",
    "### Part B:\n",
    "- Use $\\frac{1}{2+(x-4)^2}$ as your $f_X(x)$ (remember that you need to normalize your choice of $f_X$ in order for it to represent a pdf). Implement a Metropolis-Hastings algorithm to sample from $f_X$. Run the simulation 50 times for 150,000 points. Report the value of the integral $\\hat{I}$ and the Var(${\\hat{I}}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Metropolis-Hastings\n",
    "\n",
    "Suppose we ask you to memorize the order of the top five movies on IMDB. When we quiz on the order afterwards, you might not recall the correct order, but the mistakes you tend to make in your recall can be modeled by simple probabilistic models.\n",
    "  \n",
    "Let's say that the top five movies are:  \n",
    "1. *The Shawshank Redemption*\n",
    "2. *The Godfather*\n",
    "3. *The Godfather: Part II*\n",
    "4. *The Dark Knight*\n",
    "5. *Pulp Fiction*\n",
    "\n",
    "Let's represent this ordering by the vector $\\omega = (1,2,3,4,5)$. \n",
    "\n",
    "If you were to mistakenly recall the top five movies as:\n",
    "2. *The Godfather*\n",
    "3. *The Godfather: Part II*\n",
    "5. *Pulp Fiction*\n",
    "4. *The Dark Knight*\n",
    "1. *The Shawshank Redemption*\n",
    "\n",
    "We'd represent your answer by the vector $\\theta = (2,3,5,4,1)$.\n",
    "\n",
    "Now, we have a way of quantifiness how wrong your answer can be. We define the Hamming distance between two top five rankings, $\\theta, \\omega$, as follows:\n",
    "$$d(\\theta, \\omega) = \\sum_{i=1}^5 \\mathbb{I}_{\\theta_i\\neq \\omega_i},$$ \n",
    "where $\\mathbb{I}_{\\theta_i\\neq \\omega_i}$ is the indicator function that returns 1 if $\\theta_i\\neq \\omega_i$ and 0 otherwise.\n",
    "\n",
    "For example, the Hamming distance between your answer and the correct answer is $d(\\theta, \\omega)=4$, because you only ranked *The Dark Knight* is correctly. \n",
    "\n",
    "Finally, let's suppose that the probability of giving a particular answer (expressed as $\\theta$) is modeled as\n",
    "$$ p(\\theta | \\omega, \\lambda) \\propto  e^{-\\lambda d(\\theta, \\omega)}.$$\n",
    "\n",
    "### Part A:\n",
    "\n",
    "Implement an Metropolis-Hastings algorithm to produce sample guesses from 500 individuals with different $\\lambda=0.2, 0.5, 1.0$. What are the top five possible guesses?\n",
    "\n",
    "### Part B:\n",
    "Compute the probability that *The Shawshank Redemption* is ranked as the top 1 movie by the Metropolis-Hastings algorithm. Compare the results for different $\\lambda$. Summarize your findings."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
